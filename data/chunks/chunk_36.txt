play quite significant role in this case as well. Quite often like similarity metrics that systems identified this is angle between the vectors sorry straight line just distance between them and in some cases some dot multiplication in that systems. So why is like embedding quality matters because basically it's mean that how reliable answer will our user of our system will get. And right now MTB metrics to be honest I don't remember exact like this full abbreviation but I provided the link to the leaderboard and you will see what exactly it's mean what's the abbreviation. So this is the approach how to how current embedding models evaluated on the quality of their basically embeddings and accuracy of their embeddings. And in the point of time when I was preparing this presentation a few of the main or like token embedding models basically from the Google and token AI and one of the open source knowledge search but right now I guess Chinese embedding models on a good spot there as well so you can try and play. And why exactly like embedding quality matters if we will see the different case studies or researchers you will still see that any embedding model or embedding system can provide 100% of the accuracy because still LLM or like similarity search can be like mistaken mistaken interpreter and one of the like best results that you can find like on the Google website for example it's research about the legal