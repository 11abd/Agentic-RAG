getting ML algorithms. Pizza recipes is quite far so most probably system will not suggest this to us. And if we are going a bit like deeper to the exact like similarity search how it works. So we have our documents we already discussed about the rock pipeline so it's already transformed to the numerical representation from the embedded models and it stores somewhere here to the vector to the vector store. And we have like three documents and we fully indexed that documents and it's stored. And when we have a search and if we have like user query, query learn Python then based on that documents that we stored our system identified the distance for our request and in this case quite close somewhat close and far away. If we set up that we want to pick up two top results so in this case we will get Python tutorial and Java programming as well. And then LLAM may be make a decision that's to show only like Python tutorial but it can be the case that it will provide as a output to the user both like Python tutorial and Java programming because quality of the LLAM play quite significant role in this case as well. Quite often like similarity metrics that systems identified this is angle between the vectors sorry straight line just distance between them and in some cases some dot multiplication in that systems. So why is like embedding quality matters because basically it's