split our data to the smaller pieces we are converting that smaller pieces to the numeric value and then that numeric value basically ingest to the vector database and we have a step of the retrieval it's one already our user of our system basically make the request and our system based on that request making the similarity search from the vector database and based on the results of that similarity search it's choosing like top key chunks like normally you are setting that's between like five to ten top results that you're grabbing from that vector database and then lm decide what part of the information from the chunk it should pick up to fulfill the intent of the request of the user and provide the output so chunking and approach to the chunking is a quite important part of this all of the rock system because like context window of the lm lm 6 limited for most of the lm's right now for sure we have quite a huge one even within the last jemenai versions they mentioned it can the context window can grow up to two million tokens but still the problem with missing information in the middle still persist with huge with huge context that you are providing to the model to the models even right now the situation is improving and mainly labs are working quite heavily to improve the retrieval and fighting and processing of the whole of the information that you provide