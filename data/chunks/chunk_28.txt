how do we decide chunk size for document you're starting basically from that chunk size that's I provided when we have like 512 tokens and with the slide in window of 15 percentage and this is why you are starting and then based on your like further experiments quite often when we are talking about like all AI or like ML development system you always have part as a research and then you based on the results that you are getting you are playing with the numbers so based on what you get and what you reviewed or maybe you already built the evaluation pipeline based on the numbers from the evaluation pipeline you can then just change your parameters and see if you are getting better results and then based on that researches based on that evaluations you can get the best number in your case in terms of what is the size and what is the approach to the chunks should be. Thank you Maxneum we have other question from Tolani she said that she found that LLAMs struggle was analyzing survey data she had started putting the documents as PDF and found that it works better so the questions are which chunk in strategy would an LLAM use for survey in PDF format versus CSV and which do you recommend. We will talk about this in our next session. Okay. So give that question for the next session in case we will not answer. Got it and