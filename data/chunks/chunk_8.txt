iterate based on metrics ✅ Use metadata ﬁltering (product, language, permissions) ✅ Combine vector + keyword search (hybrid approach) ✅ Monitor retrieval quality (recall@k, precision) ✅ Keep embeddings synchronized with documents ✅ Evaluate with domain-speciﬁc questions Do’s and don’ts for RAG 15 15 Three Main Chunking Strategies Scenario Stack Key Reason Learning LangChain + Chroma + sentence-transformers + Ollama ● Learn fundamentals ● Risk-free ● Runs on laptop MVP LangChain + Qdrant (self-host) + OpenAI/Gemini embeddings + GPT-4o-mini Professional quality at startup budget Enterprise LangGraph + LangSmith + Pinecone + OpenAI/Gemini + GPT-4 ● Agentic workﬂows ● Observability ● SLAs 16 ✅ Chunk size: 512 tokens ✅ Chunk overlap: 15% (~75 tokens) ✅ Top-k retrieval: 3-5 chunks ✅ Embedding dimensions: 768-1536 Default Conﬁguration (Works for 80% of cases): 17 ✅ RAG = Open-book exam for AI - Retrieves external knowledge at query time ✅ Chunking is critical - Start with 512 tokens, 15% overlap, then iterate ✅ Hybrid search > vector-only - Combine vector and keyword search ✅ Start simple - Use Chroma + LangChain for learning, scale as needed ✅ Always evaluate - Track recall, precision, and answer quality Key Takeaways What You Should Remember --- 1 part. RAG Intro.txt --- As we are starting with a rock topic, today we will have a small intro and then move on to the databases for Genii. Our speaker for today's both session is Maxim and we will start with intro. As I said, Maxim, you're very welcome to start. Hello.