that you want to utilize as a part of the output than when LLM is working on that data but a lot of the researchers show them that's bigger context windows that you utilize or like bigger prompt you you provided to the LLM you are getting much worse result because LLM quite often missing the exact like needed information in the middle and in addition you just provide in some noise together with that data like some of the words or information that's even not connected to your basically use case of the database of the communication with LLM. When we are going to deep dive so in the RUG pipeline in general we have two main stages but like when we go a bit to the details quite often and especially this information is missing when you when you're reading about the like RUG pipeline it's data preparation for that RUG pipeline because mainly it's focused on like the way of the chunking about the database you can use and how you put the data but it's quite important to start from the preparation of your data because I've mentioned for example when we provide a huge amount of the data to the LLM one of the big problem that's together with the data providing like water or noise that's just can navigate LLM when it use that like prompt information or text in the wrong direction so that's why quite often preparation of the of your data