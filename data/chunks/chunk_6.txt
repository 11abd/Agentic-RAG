Pros Cons When to Use Fixed-Size Split at 512 tokens, 15% overlap Simple, fast, predictable May break mid-sentence General purpose, starting point Semantic Use ML to identify coherent units Preserves meaning, high accuracy More compute, slower Technical docs, complex content Recursive Split using separators (\n\n, \n, space) repeatedly until desired size Respects structure, better boundaries More complex than ﬁxed-size Documents with headings, paragraphs 10 10 Chunking Strategy Comparison Fixed-Size Recursive Semantic 11 11 Using Chunking Libraries You Don't Need to Build from Scratch LangChain LlamaIndex Broad LLM application framework Modular workﬂows where chunking is one piece of the puzzle ●Flexible TextSplitters ●Easy integration with agents ●Part of larger system RAG-speciﬁc pipeline High-performance, data-centric retrieval systems ●Sophisticated NodeParsers ●Produces optimized "Nodes" ●Built for ingestion/retrieval 12 12 RAG real world use cases ● AI Chatbots: RAG provides accurate answers from internal knowledge bases (e.g., support wikis, legal documents). OpenAI emphasises that RAG is valuable when the content is not part of the base model’s knowledge . ● Search & discovery: Search systems combine keyword and vector search to surface relevant documents in e‑commerce, research and legal discovery. ● AI Copilots: Tools like Supabase AI Copilots use vector databases to ground responses in proprietary data and maintain multi‑tenant isolation . ● Long‑context reasoning: Databricks’ long‑context benchmark shows that Google’s Gemini 2.5 models can maintain consistent performance on RAG tasks up to two million tokens (longer than most models), whereas OpenAI’s GPT 5 models achieve state‑of‑the‑art accuracy up to 128k tokens . 13 13