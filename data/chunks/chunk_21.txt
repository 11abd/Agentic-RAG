split the information better as well but they are coming with additional more extensive compute cost time and still we don't have like 100% reliable system that is the best approach for this splitting chunking or like embedding of the information so you don't need to implement like all of that that we mentioned like approaches to the chunks so some of the top libraries that's already fully implemented at least like basic approaches to the chunking so basically the length chain has has all of the basic approaches not only what I showed earlier in addition then they have more complex chunking approaches so it's a quiet known library like basically application framework that helping to build the agentic workflows and in under the hood it has a lot of additional connectors, side libraries that's helping us to build that agentic system and LLM index from the start it mostly was focused on the rock specific pipelines it has quite good performance it's data centric and it's just have a bit different approach how they implement this chunking strategy but you can find even the same chunking strategy implementation in both libraries so you can look there try them and most probably you will get quite good results from best in different chunk approaches for exact your cases. In terms of where mainly rock is using for sure we can we can talk about like from the perspective of general systems and from the perspective of the use cases